
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Performance Essentials &#8212; UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.6</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=466cad66"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '30-performance/performance';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compiling and Running oneAPI programs" href="../80-running/running.html" />
    <link rel="prev" title="Quantitative Finance" href="../20-quant-finance/qfi.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.6</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00-preliminaries/preliminaries.html">About the Book</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-parallel/parallel.html">Introduction to Parallel Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-software-engineering/software-engineering.html">Introduction to Software Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15-modern-cpp/modern-cpp.html">Modern C++ as a Better C (and C++)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../18-dpcpp/dpcpp.html">Data-Parallel C++ with oneAPI/SYCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20-quant-finance/qfi.html">Quantitative Finance</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Performance Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../80-running/running.html">Compiling and Running oneAPI programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../90-contributions/contributions.html">Contribution Guildelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../91-coc/code-of-conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../92-marching-cubes/marching-cubes.html">Marching Cubes: From CUDA to SYCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../93-electron-density/electron-density.html">Electron Density Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../99-chapter-template/chapter-title.html">Chapter Title</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/30-performance/performance.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Performance Essentials</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-time-performance">Measuring time performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-achieve-speedup">How to achieve speedup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-execution">Sequential execution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-execution-on-an-accelerator">Parallel execution on an accelerator</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-execution-on-a-multicore-cpu">Parallel execution on a multicore CPU</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#observed-scaling">Observed scaling</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="performance-essentials">
<h1>Performance Essentials<a class="headerlink" href="#performance-essentials" title="Link to this heading">#</a></h1>
<p>In this section, we discuss various aspects of performance of data-parallel C++ code, including how we can measure time performance in terms of elapsed “wall clock” time, and how we can achieve and observe a speedup when leveraging data parallelism.</p>
<section id="measuring-time-performance">
<h2>Measuring time performance<a class="headerlink" href="#measuring-time-performance" title="Link to this heading">#</a></h2>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">chrono</span></code> section of the C++ Standard Library for measuring performance at various points during program execution.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">mark_time</span><span class="p">(</span><span class="n">ts_vector</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">timestamps</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">label</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">timestamps</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">()));</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Every time we want to add a timestamp, we invoke <code class="docutils literal notranslate"><span class="pre">mark_time</span></code> with a suitable string label for each phase whose performance we are measuring:</p>
<ul class="simple">
<li><p>memory allocation</p></li>
<li><p>queue creation</p></li>
<li><p>core computation (e.g., integration)</p></li>
<li><p>remainder of execution (e.g., displaying the results)</p></li>
<li><p>total wall clock execution time</p></li>
</ul>
<p>At the end, we use the <code class="docutils literal notranslate"><span class="pre">print_timestamps</span></code> function to print the collected measurements in comma-separated-values (CSV) format, as shown in the sample runs below.</p>
</section>
<section id="how-to-achieve-speedup">
<h2>How to achieve speedup<a class="headerlink" href="#how-to-achieve-speedup" title="Link to this heading">#</a></h2>
<p>As discussed in the previous chapter, at the core of data parallelism lies the ability to perform many operations on similar data in parallel at the hardware level.
Beyond Amdah’s law, there is a tradeoff between the speedup gained through parallelization and the additional overhead of shipping data back and forth between the host computer and the accelerator.
To understand this tradeoff, we are separately measuring the various phases of program execution as shown above.</p>
<p>For the following experiments, we are going use the following integrand (function to be integrated):</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In addition, we have factored out the following function to compute (sequentially) a single outer trapezoid from as many inner trapezoids as the grain size, which we can specify as a command-line argument.
We invoke this common function from both the outer sequential loop and the outer vectorized <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> construct.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// common function to compute a single outer trapezoid</span>
<span class="c1">// from as many inner trapezoids as the grain size</span>
<span class="kt">double</span><span class="w"> </span><span class="nf">outer_trapezoid</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">grain_size</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x_pos</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dx_inner</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">half_dx_inner</span>
<span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">area</span><span class="p">{</span><span class="mf">0.0</span><span class="p">};</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">y_left</span><span class="p">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)};</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">j</span><span class="p">{</span><span class="mi">0UL</span><span class="p">};</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">grain_size</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">y_right</span><span class="p">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_pos</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dx_inner</span><span class="p">)};</span>
<span class="w">        </span><span class="n">area</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">single_trapezoid</span><span class="p">(</span><span class="n">y_left</span><span class="p">,</span><span class="w"> </span><span class="n">y_right</span><span class="p">,</span><span class="w"> </span><span class="n">half_dx_inner</span><span class="p">);</span>
<span class="w">        </span><span class="n">y_left</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_right</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">area</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In this way, the actual effort becomes significantly greater than the overhead from setup, so we are likely to observe a greater benefit from parallelization.</p>
<p>We will now compare wall clock execution times on our academic department’s compute server with the following characteristics:</p>
<ul class="simple">
<li><p>dual AMD EPYC 9354 32-Core processors</p></li>
<li><p>six NVIDIA RTX A6000 GPUs (though we will be using only one at a time for now)</p></li>
</ul>
<section id="sequential-execution">
<h3>Sequential execution<a class="headerlink" href="#sequential-execution" title="Link to this heading">#</a></h3>
<p>We start with strictly sequential execution on the node’s CPU using the <cite>-s</cite> option of our integration example.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build/bin/integration -n 100000000000 -g 100 -s
[2023-12-02 09:53:18.563] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-02 09:53:20.463] [info] starting sequential integration
[2023-12-02 09:58:46.057] [info] result should be available now
result = 1.0000000000000597
[2023-12-02 09:58:46.202] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
68410926133405,0,ns,sequential,Start
68412826265635,1900132230,ns,sequential,Memory allocation
68738419748223,325593482588,ns,sequential,Integration
68738565342993,145594770,ns,sequential,DONE
68738565342993,327639209588,ns,sequential,TOTAL
</pre></div>
</div>
<p>The total wall time for this sequential run was about 328 seconds.</p>
</section>
<section id="parallel-execution-on-an-accelerator">
<h3>Parallel execution on an accelerator<a class="headerlink" href="#parallel-execution-on-an-accelerator" title="Link to this heading">#</a></h3>
<p>Next, we allow our integration code to select and utilize the available accelerator.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build-nvidia/bin/integration -n 100000000000 -g 100
[2023-12-02 00:42:30.267] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-02 00:42:30.267] [info] preparing for vectorized integration
[2023-12-02 00:42:30.832] [info] Device: NVIDIA RTX A6000
[2023-12-02 00:42:30.837] [info] done submitting to queue...waiting for results
[2023-12-02 00:43:03.964] [info] result should be available now
result = 1.0000000000000002
[2023-12-02 00:43:03.971] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
35362630446292,0,ns,NVIDIA RTX A6000,Start
35362630466323,20031,ns,NVIDIA RTX A6000,Memory allocation
35363195459619,564993296,ns,NVIDIA RTX A6000,Queue creation
35396327471267,33132011648,ns,NVIDIA RTX A6000,Integration
35396333911606,6440339,ns,NVIDIA RTX A6000,DONE
35396333911606,33703465314,ns,NVIDIA RTX A6000,TOTAL
</pre></div>
</div>
<p>The total wall time for this run was about 33.7 seconds, including the overhead for preparing the task queue and shipping any required data back and forth.
This corresponds to a speedup of about 10 compared to sequential execution.</p>
<p>These measurements lead to various insights on what is going “under the hood” during program execution, to name a few:</p>
<ul class="simple">
<li><p>Initial allocation of a SYCL buffer takes very little time compared to allocating a standard vector.</p></li>
<li><p>Queue creation introduces a certain overhead, comparable to allocation a vector on the host CPU.</p></li>
</ul>
</section>
<section id="parallel-execution-on-a-multicore-cpu">
<h3>Parallel execution on a multicore CPU<a class="headerlink" href="#parallel-execution-on-a-multicore-cpu" title="Link to this heading">#</a></h3>
<p>Our examples also support a <cite>-c</cite> option for executing data-parallel code on the host CPU itself.
This is reasonable when the CPU already has multiple cores.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build/bin/integration -n 100000000000 -g 100 -c
[2023-12-03 22:34:05.010] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-03 22:34:05.010] [info] preparing for vectorized integration
[2023-12-03 22:34:05.582] [info] Device: AMD EPYC 9354 32-Core Processor
[2023-12-03 22:34:05.803] [info] done submitting to queue...waiting for results
[2023-12-03 22:34:06.578] [info] result should be available now
result = 1.0000000000000009
[2023-12-03 22:34:06.967] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
200457373084707,0,ns,AMD EPYC 9354 32-Core Processor,Start
200457373102067,17360,ns,AMD EPYC 9354 32-Core Processor,Memory allocation
200457945058810,571956743,ns,AMD EPYC 9354 32-Core Processor,Queue creation
200458940879950,995821140,ns,AMD EPYC 9354 32-Core Processor,Integration
200459329758480,388878530,ns,AMD EPYC 9354 32-Core Processor,DONE
200459329758480,1956673773,ns,AMD EPYC 9354 32-Core Processor,TOTAL
</pre></div>
</div>
<p>The total wall time for this run was about 1.96 seconds, including the overhead for preparing the task queue on the host CPU.
This corresponds to a speedup of about 165 compared to sequential execution or a speedup of about 17 compared to execution on the GPU, possibly because of the better support for 64-bit floating point arithmetic on the CPU.</p>
</section>
</section>
<section id="observed-scaling">
<h2>Observed scaling<a class="headerlink" href="#observed-scaling" title="Link to this heading">#</a></h2>
<p>In this section, we’ll share our high-level observations of scaling in terms of the total workload (number of trapezoids) n and the grain size (number of inner, always sequential trapezoids) g, for our three execution modes:</p>
<ul class="simple">
<li><p>sequential execution</p></li>
<li><p>parallel execution on a single NVIDIA RTX A6000 GPU</p></li>
<li><p>parallel execution on dual AMD EPYC 9354 32-Core processors</p></li>
</ul>
<p>Each chart shows a scatter plot with several color-coded series corresponding to total workload.
The x-axis shows grain size, and the y-axis shows wall time in seconds.
Axis ranges and series colors are consistent across charts, thereby allowing a direct comparison of measurements for a given workload and grain size.</p>
<figure class="align-default">
<img alt="../_images/walltime-seq.png" src="../_images/walltime-seq.png" />
</figure>
<p>As expected, for sequential execution, wall time is proportional to total workload and independent of grain size.
(We discontinued the experiment for the highest workload only to save some time.)</p>
<figure class="align-default">
<img alt="../_images/walltime-gpu.png" src="../_images/walltime-gpu.png" />
</figure>
<p>For parallel execution on the GPU, we are achieving a speedup of about 10 (one full order of magnitude).
Otherwise, wall time is still proportional to total workload and mostly independent of grain size; excessive grain size, however, appears to overload GPU cores and can even result in a slowdown relative to sequential execution.
In this and the next chart, the missing data points for smaller grain sizes are caused by the resulting range of the <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> becoming larger than <code class="docutils literal notranslate"><span class="pre">INT_MAX</span></code>.</p>
<figure class="align-default">
<img alt="../_images/walltime-cpu.png" src="../_images/walltime-cpu.png" />
</figure>
<p>For parallel execution on the CPU, we are achieving of almost three orders of magnitude relative to sequential execution, and almost two orders of magnitude relative to parallel execution on the GPU.
Otherwise, wall time proportional (slightly sublinear) to total workload and mostly independent of grain size, except for a certain overhead for small grain sizes that put an insufficient load on each processor core.</p>
<p>In addition, our raw performance data are <a class="reference external" href="https://docs.google.com/spreadsheets/d/1NUD_yqfwgUr9XYucRgMykKDrgUAETmvC4mzOMVDxDZY">available in this spreadsheet</a>.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../20-quant-finance/qfi.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quantitative Finance</p>
      </div>
    </a>
    <a class="right-next"
       href="../80-running/running.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compiling and Running oneAPI programs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-time-performance">Measuring time performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-achieve-speedup">How to achieve speedup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-execution">Sequential execution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-execution-on-an-accelerator">Parallel execution on an accelerator</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-execution-on-a-multicore-cpu">Parallel execution on a multicore CPU</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#observed-scaling">Observed scaling</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Author name not set
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023-Present, George K. Thiruvathukal and Konstantin Läufer.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>