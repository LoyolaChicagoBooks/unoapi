<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" metia="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Performance Essentials | UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1</title>
<meta content="Performance Essentials | UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1" property="og:title"/>
<meta content="Performance Essentials | UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1" name="twitter:title"/>
<link href="../_static/pygments.css?v=fa44fd50" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=7112734b" rel="stylesheet" type="text/css"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../80-running/running.html" rel="next" title="Compiling and Running oneAPI programs"/>
<link href="../20-quant-finance/qfi.html" rel="prev" title="Quantitative Finance"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a>
<header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../index.html"><span class="font-bold text-clip whitespace-nowrap">UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../00-preliminaries/preliminaries.html">About the Book</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-parallel/parallel.html">Introduction to Parallel Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-software-engineering/software-engineering.html">Introduction to Software Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15-modern-cpp/modern-cpp.html">Modern C++ as a Better C (and C++)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../18-dpcpp/dpcpp.html">Data-Parallel C++ with oneAPI/SYCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20-quant-finance/qfi.html">Quantitative Finance</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../80-running/running.html">Compiling and Running oneAPI programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">UnoAPI: Modern Parallel C++ Programming with SYCL and oneAPI v0.5.1</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Performance Essentials</span>
</nav>
<div id="content" role="main">
<section id="performance-essentials">
<h1>Performance Essentials<a class="headerlink" href="#performance-essentials" title="Link to this heading">¶</a></h1>
<p>In this section, we discuss various aspects of performance of data-parallel C++ code, including how we can measure time performance in terms of elapsed “wall clock” time, and how we can achieve and observe a speedup when leveraging data parallelism.</p>
<section id="measuring-time-performance">
<h2>Measuring time performance<a class="headerlink" href="#measuring-time-performance" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#measuring-time-performance'">¶</a></h2>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">chrono</span></code> section of the C++ Standard Library for measuring performance at various points during program execution.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">mark_time</span><span class="p">(</span>
<span class="w">  </span><span class="n">ts_vector</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">timestamps</span><span class="p">,</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">label</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">timestamps</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">()));</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>use code snippet instead</p>
</div>
<p>Every time we want to add a timestamp, we invoke <code class="docutils literal notranslate"><span class="pre">mark_time</span></code> with a suitable string label for each phase whose performance we are measuring:</p>
<ul class="simple">
<li><p>memory allocation</p></li>
<li><p>queue creation</p></li>
<li><p>core computation (e.g., integration)</p></li>
<li><p>remainder of execution (e.g., displaying the results)</p></li>
<li><p>total wall clock execution time</p></li>
</ul>
<p>At the end, we use the <code class="docutils literal notranslate"><span class="pre">print_timestamps</span></code> function to print the collected measurements in comma-separated-values (CSV) format, as shown in the sample runs below.</p>
</section>
<section id="how-to-achieve-speedup">
<h2>How to achieve speedup<a class="headerlink" href="#how-to-achieve-speedup" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#how-to-achieve-speedup'">¶</a></h2>
<p>As discussed in the previous chapter, at the core of data parallelism lies the ability to perform many operations on similar data in parallel at the hardware level.
Beyond Amdah’s law, there is a tradeoff between the speedup gained through parallelization and the additional overhead of shipping data back and forth between the host computer and the accelerator.
To understand this tradeoff, we are separately measuring the various phases of program execution as shown above.</p>
<p>For the following experiments, we are going use the following integrand (function to be integrated):</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>use code snippet instead</p>
</div>
<p>In addition, we have factored out the following function to compute (sequentially) a single outer trapezoid from as many inner trapezoids as the grain size, which we can specify as a command-line argument.
We invoke this common function from both the outer sequential loop and the outer vectorized <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> construct.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="nf">compute_outer_trapezoid</span><span class="p">(</span>
<span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">grain_size</span><span class="p">,</span>
<span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x_pos</span><span class="p">,</span>
<span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">dx_inner</span><span class="p">,</span>
<span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">half_dx_inner</span>
<span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">   </span><span class="k">auto</span><span class="w"> </span><span class="n">area</span><span class="p">{</span><span class="mf">0.0</span><span class="p">};</span>
<span class="w">   </span><span class="k">auto</span><span class="w"> </span><span class="n">y_left</span><span class="p">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)};</span>
<span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">j</span><span class="p">{</span><span class="mi">0UL</span><span class="p">};</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">grain_size</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">y_right</span><span class="p">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_pos</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dx_inner</span><span class="p">)};</span>
<span class="w">      </span><span class="n">area</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">trapezoid</span><span class="p">(</span><span class="n">y_left</span><span class="p">,</span><span class="w"> </span><span class="n">y_right</span><span class="p">,</span><span class="w"> </span><span class="n">half_dx_inner</span><span class="p">);</span>
<span class="w">      </span><span class="n">y_left</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_right</span><span class="p">;</span>
<span class="w">   </span><span class="p">}</span>
<span class="w">   </span><span class="k">return</span><span class="w"> </span><span class="n">area</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>use code snippet instead</p>
</div>
<p>In this way, the actual effort becomes significantly greater than the overhead from setup, so we are likely to observe a greater benefit from parallelization.</p>
<p>We will now compare wall clock execution times on our academic department’s compute server with the following characteristics:</p>
<ul class="simple">
<li><p>dual AMD EPYC 9354 32-Core processors</p></li>
<li><p>six NVIDIA RTX A6000 GPUs (though we will be using only one at a time for now)</p></li>
</ul>
<section id="sequential-execution">
<h3>Sequential execution<a class="headerlink" href="#sequential-execution" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#sequential-execution'">¶</a></h3>
<p>We start with strictly sequential execution on the node’s CPU using the <cite>-s</cite> option of our integration example.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build/bin/integration -n 100000000000 -g 100 -s
[2023-12-02 09:53:18.563] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-02 09:53:20.463] [info] starting sequential integration
[2023-12-02 09:58:46.057] [info] result should be available now
result = 1.0000000000000597
[2023-12-02 09:58:46.202] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
68410926133405,0,ns,sequential,Start
68412826265635,1900132230,ns,sequential,Memory allocation
68738419748223,325593482588,ns,sequential,Integration
68738565342993,145594770,ns,sequential,DONE
68738565342993,327639209588,ns,sequential,TOTAL
</pre></div>
</div>
<p>The total wall time for this sequential run was about 328 seconds.</p>
</section>
<section id="parallel-execution-on-an-accelerator">
<h3>Parallel execution on an accelerator<a class="headerlink" href="#parallel-execution-on-an-accelerator" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#parallel-execution-on-an-accelerator'">¶</a></h3>
<p>Next, we allow our integration code to select and utilize the available accelerator.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build-nvidia/bin/integration -n 100000000000 -g 100
[2023-12-02 00:42:30.267] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-02 00:42:30.267] [info] preparing for vectorized integration
[2023-12-02 00:42:30.832] [info] Device: NVIDIA RTX A6000
[2023-12-02 00:42:30.837] [info] done submitting to queue...waiting for results
[2023-12-02 00:43:03.964] [info] result should be available now
result = 1.0000000000000002
[2023-12-02 00:43:03.971] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
35362630446292,0,ns,NVIDIA RTX A6000,Start
35362630466323,20031,ns,NVIDIA RTX A6000,Memory allocation
35363195459619,564993296,ns,NVIDIA RTX A6000,Queue creation
35396327471267,33132011648,ns,NVIDIA RTX A6000,Integration
35396333911606,6440339,ns,NVIDIA RTX A6000,DONE
35396333911606,33703465314,ns,NVIDIA RTX A6000,TOTAL
</pre></div>
</div>
<p>The total wall time for this run was about 33.7 seconds, including the overhead for preparing the task queue and shipping any required data back and forth.
This corresponds to a speedup of about 10 compared to sequential execution.</p>
<p>These measurements lead to various insights on what is going “under the hood” during program execution, to name a few:</p>
<ul class="simple">
<li><p>Initial allocation of a SYCL buffer takes very little time compared to allocating a standard vector.</p></li>
<li><p>Queue creation introduces a certain overhead, comparable to allocation a vector on the host CPU.</p></li>
</ul>
</section>
<section id="parallel-execution-on-a-multicore-cpu">
<h3>Parallel execution on a multicore CPU<a class="headerlink" href="#parallel-execution-on-a-multicore-cpu" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#parallel-execution-on-a-multicore-cpu'">¶</a></h3>
<p>Our examples also support a <cite>-c</cite> option for executing data-parallel code on the host CPU itself.
This is reasonable when the CPU already has multiple cores.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&gt; ./build/bin/integration -n 100000000000 -g 100 -c
[2023-12-03 22:34:05.010] [info] integrating function from 0 to 1 using 100000000000 trapezoid(s) with grain size 100, dx = 1e-09
[2023-12-03 22:34:05.010] [info] preparing for vectorized integration
[2023-12-03 22:34:05.582] [info] Device: AMD EPYC 9354 32-Core Processor
[2023-12-03 22:34:05.803] [info] done submitting to queue...waiting for results
[2023-12-03 22:34:06.578] [info] result should be available now
result = 1.0000000000000009
[2023-12-03 22:34:06.967] [info] all done for now
TIME,DELTA,UNIT,DEVICE,PHASE
200457373084707,0,ns,AMD EPYC 9354 32-Core Processor,Start
200457373102067,17360,ns,AMD EPYC 9354 32-Core Processor,Memory allocation
200457945058810,571956743,ns,AMD EPYC 9354 32-Core Processor,Queue creation
200458940879950,995821140,ns,AMD EPYC 9354 32-Core Processor,Integration
200459329758480,388878530,ns,AMD EPYC 9354 32-Core Processor,DONE
200459329758480,1956673773,ns,AMD EPYC 9354 32-Core Processor,TOTAL
</pre></div>
</div>
<p>The total wall time for this run was about 1.96 seconds, including the overhead for preparing the task queue on the host CPU.
This corresponds to a speedup of about 165 compared to sequential execution or a speedup of about 17 compared to execution on the GPU, possibly because of the better support for 64-bit floating point arithmetic on the CPU.</p>
</section>
</section>
<section id="observed-scaling">
<h2>Observed scaling<a class="headerlink" href="#observed-scaling" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#observed-scaling'">¶</a></h2>
<p>In this section, we’ll share our high-level observations of scaling in terms of the total workload (number of trapezoids) n and the grain size (number of inner, always sequential trapezoids) g, for our three execution modes:</p>
<ul class="simple">
<li><p>sequential execution</p></li>
<li><p>parallel execution on a single NVIDIA RTX A6000 GPU</p></li>
<li><p>parallel execution on dual AMD EPYC 9354 32-Core processors</p></li>
</ul>
<p>Each chart shows a scatter plot with several color-coded series corresponding to total workload.
The x-axis shows grain size, and the y-axis shows wall time in seconds.
Axis ranges and series colors are consistent across charts, thereby allowing a direct comparison of measurements for a given workload and grain size.</p>
<figure class="align-default">
<img alt="../_images/walltime-seq.png" src="../_images/walltime-seq.png"/>
</figure>
<p>As expected, for sequential execution, wall time is proportional to total workload and independent of grain size.
(We discontinued the experiment for the highest workload only to save some time.)</p>
<figure class="align-default">
<img alt="../_images/walltime-gpu.png" src="../_images/walltime-gpu.png"/>
</figure>
<p>For parallel execution on the GPU, we are achieving a speedup of about 10 (one full order of magnitude).
Otherwise, wall time is still proportional to total workload and mostly independent of grain size; excessive grain size, however, appears to overload GPU cores and can even result in a slowdown relative to sequential execution.
In this and the next chart, the missing data points for smaller grain sizes are caused by the resulting range of the <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> becoming larger than <code class="docutils literal notranslate"><span class="pre">INT_MAX</span></code>.</p>
<figure class="align-default">
<img alt="../_images/walltime-cpu.png" src="../_images/walltime-cpu.png"/>
</figure>
<p>For parallel execution on the CPU, we are achieving of almost three orders of magnitude relative to sequential execution, and almost two orders of magnitude relative to parallel execution on the GPU.
Otherwise, wall time proportional (slightly sublinear) to total workload and mostly independent of grain size, except for a certain overhead for small grain sizes that put an insufficient load on each processor core.</p>
<p>In addition, our raw performance data are <a class="reference external" href="https://docs.google.com/spreadsheets/d/1NUD_yqfwgUr9XYucRgMykKDrgUAETmvC4mzOMVDxDZY">available in this spreadsheet</a>.</p>
</section>
</section>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(var(--vh)-4rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#measuring-time-performance'" class="reference internal" href="#measuring-time-performance">Measuring time performance</a></li>
<li><a :data-current="activeSection === '#how-to-achieve-speedup'" class="reference internal" href="#how-to-achieve-speedup">How to achieve speedup</a><ul>
<li><a :data-current="activeSection === '#sequential-execution'" class="reference internal" href="#sequential-execution">Sequential execution</a></li>
<li><a :data-current="activeSection === '#parallel-execution-on-an-accelerator'" class="reference internal" href="#parallel-execution-on-an-accelerator">Parallel execution on an accelerator</a></li>
<li><a :data-current="activeSection === '#parallel-execution-on-a-multicore-cpu'" class="reference internal" href="#parallel-execution-on-a-multicore-cpu">Parallel execution on a multicore CPU</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#observed-scaling'" class="reference internal" href="#observed-scaling">Observed scaling</a></li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2023-Present, George K. Thiruvathukal and Konstantin Läufer Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 7.2.6</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=421b0634"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=e8bd915e"></script>
</body>
</html>